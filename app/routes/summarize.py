from fastapi import APIRouter, HTTPException, Depends
from app.utils.extractor import extract_text_from_pdf, extract_text_from_docx
import google.generativeai as genai
from app.database import get_db
from app.models.document import Document
import os, mimetypes
from sqlalchemy.orm import Session
from app.utils.hierarchical_summarizer import HierarchicalSummarizer
import logging
from app.routes.auth import get_current_user
from app.models.user import User

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

UPLOAD_DIR = "uploaded_files"  # Update this path to your desired UPLOAD_DIR location
router = APIRouter()

genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

@router.post("/summarize/{filename}")
def summarize_file(filename: str, db: Session = Depends(get_db), current_user: User = Depends(get_current_user)):
    document = db.query(Document).filter(Document.filename == filename, Document.user_id == current_user.id).first()
    if not document:
        raise HTTPException(status_code=404, detail="File not found in DB")

    # Ensure document is vectorized before summarization
    if not document.is_vectorized:
        raise HTTPException(status_code=400, detail="Document must be vectorized before summarization.")

    # Calculate and set file hash if not already set
    if not document.file_hash:
        file_path = document.path
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail=f"File not found at path: {file_path}")
        import hashlib
        with open(file_path, "rb") as f:
            file_bytes = f.read()
            file_hash = hashlib.md5(file_bytes).hexdigest()
        document.file_hash = file_hash
        db.commit()
    else:
        file_path = document.path

    # If this document already has a summary for this user, return it
    if document.summary:
        return {
            "filename": filename,
            "summary": document.summary,
            "message": "Summary already generated by you, fetched from database"
        }

    # Check for existing summary by file_hash
    existing_summary_doc = db.query(Document).filter(
        Document.file_hash == document.file_hash,
        Document.summary != None
    ).first()
    if existing_summary_doc and existing_summary_doc.summary:
        document.summary = existing_summary_doc.summary
        db.commit()
        msg = "Summary already generated by you, fetched from database" if existing_summary_doc.user_id == current_user.id else "Summary already generated by another user, fetched from database"
        return {
            "filename": filename,
            "summary": document.summary,
            "message": msg
        }

    # Use the path stored in the document instead of constructing it
    file_path = document.path
    
    logger.info(f"‚û°Ô∏è Requested file for summarization: {file_path}")

    # Check if file exists
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail=f"File not found at path: {file_path}")

    mime_type, _ = mimetypes.guess_type(file_path)
    logger.info(f"üì¶ MIME type: {mime_type}")

    try:
        if mime_type == "application/pdf":
            text = extract_text_from_pdf(file_path)
        elif mime_type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            text = extract_text_from_docx(file_path)
        elif mime_type == "text/plain":  # Add support for .txt files
            with open(file_path, 'r', encoding='utf-8') as file:
                text = file.read()
        else:
            raise HTTPException(status_code=400, detail="Unsupported file type")
    except Exception as extract_err:
        raise HTTPException(status_code=500, detail=f"Text extraction error: {str(extract_err)}")

    if not text.strip():
        raise HTTPException(status_code=400, detail="Extracted text is empty")

    # Check document size upfront to prevent API quota exhaustion
    doc_size_kb = len(text) / 1024
    MAX_DOC_SIZE_KB = 1000
    
    if doc_size_kb > MAX_DOC_SIZE_KB:
        logger.warning(f"‚ö†Ô∏è Document too large ({doc_size_kb:.2f}KB) - skipping API processing")
        
        placeholder_summary = (
            f"This document is too large to summarize with the current API quota limitations. "
            f"The document contains approximately {int(doc_size_kb)}KB of text, which exceeds "
            f"our processing threshold of {MAX_DOC_SIZE_KB}KB. Please try a smaller document or "
            f"contact support for assistance with large document processing."
        )
        document.summary = placeholder_summary
        db.commit()
        
        return {
            "filename": filename,
            "summary": placeholder_summary,
            "message": "Document too large to summarize with current API quota",
            "document_size_kb": round(doc_size_kb, 2)
        }

    try:
        # Initialize the hierarchical summarizer
        summarizer = HierarchicalSummarizer(
            model_name="gemini-1.5-flash-latest",
            temperature=0.1,
            max_tokens_per_chunk=4000,
            chunk_overlap=400,
            max_retries=3
        )
        
        # Run the summarization pipeline
        result = summarizer.summarize(text)
        final_summary = result["summary"]
        
        logger.info("‚úÖ Summary complete.")
        logger.info(f"üìä Used {result['api_calls']} API calls for {result['sections_used']} sections")
        
        # Save the summary to the database
        document.summary = final_summary
        db.commit()
        
        return {
            "filename": filename,
            "summary": final_summary,
            "sections_used": result["sections_used"],
            "batches_used": result["batches_used"],
            "api_calls": result["api_calls"]
        }
    except Exception as e:
        logger.error(f"‚ö†Ô∏è Summarization failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Summarization failed: {str(e)}")

# Add a route that accepts a request body with filename
from pydantic import BaseModel

class SummarizeRequest(BaseModel):
    filename: str

@router.post("/summarize")
def summarize_file_body(request: SummarizeRequest, db: Session = Depends(get_db), current_user: User = Depends(get_current_user)):
    # Reuse the existing implementation
    return summarize_file(request.filename, db, current_user)
